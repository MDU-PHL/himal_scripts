params {
    output_dir = 'results'
    mlst_conda_env = '/home/khhor/conda/envs/mlst'
    mlst_blastdb = '/home/mdu/resources/mlst/blast/mlst.fa'
    mlst_datadir = '/home/mdu/resources/mlst/pubmlst'
    
    accession_file = 'unique_accession_italy.txt'

    // for nextflow_mlst.nf
    // genome_pattern = '/home/mdu/analysis/sharepoint/2025/CG_2024-02-26_K_pneumoniae_ST101_Italy/other-analysis/ncbi_datasets/kpneumo_kpc3_italy_pathogen_detection/ncbi_dataset/data/*/*'
    genome_pattern = '/home/mdu/analysis/sharepoint/2025/CG_2024-02-26_K_pneumoniae_ST101_Italy/other-analysis/ncbi_datasets/kpneumo_kpc3_pathogen_detection/ncbi_dataset/data/*/*'

}

conda.enabled = true

process {
    executor = 'local'
    cpus = 1
    memory = '4 GB'
    cache = 'lenient'
    
    // Rate limiting - only running 3 NCBI download processes at a time
    withName: 'DOWNLOAD_GENOME' {
        maxForks = 3
    }
    
    // Allow more MLST processes to run in parallel
    withName: 'RUN_MLST' {
        maxForks = 200
    }
}

executor {
    name = 'local'
    cpus = 100  // Adjust based on your system
    queueSize = 50
}

// Define timestamp as a variable
def timestamp = new java.text.SimpleDateFormat("yyyyMMdd_HHmmss").format(new java.util.Date())
//     file = "pipeline_trace_${timestamp}.txt"

trace {
    enabled = true
    file = 'pipeline_trace.txt'
    fields = ['task_id', 'hash', 'name', 'status', 'exit', 'submit', 'start', 'complete', 'duration', 'realtime', 'cpus', 'peak_rss', 'peak_vmem', 'rchar', 'wchar']
    overwrite = true
}

report {
    enabled = true
    file = 'pipeline_report.html'
    overwrite = true
}

timeline {
    enabled = true
    file = 'pipeline_timeline.html'
    overwrite = true
}

dag {
    enabled = true
    file = 'pipeline_dag.html'
    overwrite = true
}